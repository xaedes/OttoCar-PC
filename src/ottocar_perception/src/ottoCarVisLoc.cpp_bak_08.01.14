#include <ros/ros.h>
#include <image_transport/image_transport.h>
#include <cv_bridge/cv_bridge.h>
#include <sensor_msgs/image_encodings.h>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>

#include <cv.h>
#include <cxcore.h>
#include <math.h>
#include <vector>
#include <stdio.h>

#include <iostream>
#include <fstream>
//#include <conio.h>
#include <ctime>

//using namespace cv;


// ----------
// Parameters
// ----------
static const std::string OPENCV_WINDOW_rgb = "Image window rgb";
static const std::string OPENCV_WINDOW_topview = "Image window topview";
static const std::string OPENCV_WINDOW_lines_hor = "Image window line detection horizontal";
static const std::string OPENCV_WINDOW_lines_vert = "Image window line detection vertical";
static const std::string OPENCV_WINDOW_lanes_hor = "Image window lane classification horizontal";
static const std::string OPENCV_WINDOW_lanes_vert = "Image window lane classification vertical";

const char* projMatFilename = "visLoc_TopviewCalib_ProjMat.txt";
const char* configFilename = "visLoc_TopviewCalib_Config.txt";

bool resizeTopviewOutput = true;
bool visCarPos = false;

// Lane Mark Detection
int NEIGHBOR_KERNEL_SIZE = 65;
cv::Scalar TOPVIEW_BACKGROUND = cv::Scalar(255,255,255);
int TOPVIEW_BACKGROUND_GRAY = (int) (TOPVIEW_BACKGROUND[0] + TOPVIEW_BACKGROUND[1] + TOPVIEW_BACKGROUND[2])/ 3;
int LINE_DETECTION_THRESHOLD = 40;
    

class OttoCarVisLoc{
     ros::NodeHandle nh_;
     image_transport::ImageTransport it_;
     image_transport::Subscriber image_sub_rgb;
     //image_transport::Publisher image_pub_rgb;
     //image_transport::Subscriber image_sub_depth;
     //image_transport::Publisher image_pub_depth;
     //cv::Mat depth_img_mono8;
     cv::Mat rgb_img, topview_img, H, lines_img_hor, lines_img_vert, lanes_img_hor,lanes_img_vert, meanNeighborKernel;
     cv::Size topviewSize;
     cv::Point carPos;


    public:
    OttoCarVisLoc(): it_(nh_)
    {
        // load CalibConfig and TopviewProjMat
        H.create(3,3,CV_64F);
        loadDoubleMatFromFile(H, projMatFilename, 3, 3);
        loadCalibConfigFromFile(topviewSize, carPos, configFilename);

        // Subscrive to input video feed and publish output video feed
        image_sub_rgb = it_.subscribe("/camera/rgb/image_color", 1, &OttoCarVisLoc::imageMsgConvert_rgb, this);
        //image_pub_rgb = it_.advertise("/image_converter/image_rgb", 1);

        cv::namedWindow(OPENCV_WINDOW_rgb);        
        cv::namedWindow(OPENCV_WINDOW_topview);
        cv::namedWindow(OPENCV_WINDOW_lines_hor);
        cv::namedWindow(OPENCV_WINDOW_lines_vert);
        cv::namedWindow(OPENCV_WINDOW_lanes_hor);
        cv::namedWindow(OPENCV_WINDOW_lanes_vert);
    }

    ~OttoCarVisLoc()
    {
        cv::destroyWindow(OPENCV_WINDOW_rgb);
        cv::destroyWindow(OPENCV_WINDOW_topview);
        cv::destroyWindow(OPENCV_WINDOW_lines_hor);
        cv::destroyWindow(OPENCV_WINDOW_lines_vert);
        cv::destroyWindow(OPENCV_WINDOW_lanes_hor);
        cv::destroyWindow(OPENCV_WINDOW_lanes_vert);
    }

    void imageMsgConvert_rgb(const sensor_msgs::ImageConstPtr& msg)
    {
        cv_bridge::CvImagePtr cv_ptr;
        try
        {
            cv_ptr = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::BGR8);
        }
        catch (cv_bridge::Exception& e)
        {
            ROS_ERROR("cv_bridge exception: %s", e.what());
            return;
        }

        rgb_img = cv::Mat(cv_ptr->image.size(), CV_8UC3);
        cv_ptr->image.copyTo(rgb_img);


        //process on input
        processImage(rgb_img);

        //image_sub_rgb.shutdown();

        // Output modified video stream
        //image_pub_rgb.publish(cv_ptr->toImageMsg());cv::FileStorage file("some_name.ext", cv::FileStorage::WRITE);
    }

    void processImage(cv::Mat& inputImg)
    {
        //init images
        if(topview_img.empty())
        {
            topview_img = inputImg.clone();
            lines_img_hor = inputImg.clone();
            lines_img_vert = inputImg.clone();
            lanes_img_hor = inputImg.clone();
            lanes_img_vert = inputImg.clone();
        }

        clock_t startProcess= clock();

        // process Topview projection
        clock_t startBirdsEye = clock();
        birdsEyeTransform(inputImg, topview_img, H, topviewSize);
        postprocessTopview(topview_img, resizeTopviewOutput, carPos, visCarPos);
        clock_t endBirdsEye = clock();
        double TimeTopview = diffclock(startBirdsEye, endBirdsEye);

        // Lane Mark Detection
        // init kernel
        if(meanNeighborKernel.empty())
        {
            createMeanNeighborKernel(meanNeighborKernel, NEIGHBOR_KERNEL_SIZE);
        }
        clock_t startLaneMarks = clock();
        detectLaneMarks(topview_img, lines_img_hor, lines_img_vert, lanes_img_hor, lanes_img_vert, carPos, meanNeighborKernel);
        clock_t endLaneMarks = clock();
        double TimeLaneMarks = diffclock(startLaneMarks, endLaneMarks);

        clock_t endProcess = clock();
        double TimeProcess = diffclock(startProcess, endProcess);

        // ------
        // OUTPUT
        // ------
        ROS_INFO_STREAM("===========================================");
        ROS_INFO_STREAM("Time Topview: " << TimeTopview << "millisec" );
        ROS_INFO_STREAM("Time LaneMarks: " << TimeLaneMarks << "millisec" );
        ROS_INFO_STREAM("Time Process: " << TimeProcess << "millisec" );

        cv::imshow(OPENCV_WINDOW_rgb, inputImg);
        cv::imshow(OPENCV_WINDOW_topview, topview_img);
        cv::imshow(OPENCV_WINDOW_lines_hor, lines_img_hor);
        cv::imshow(OPENCV_WINDOW_lines_vert, lines_img_vert);
        cv::imshow(OPENCV_WINDOW_lanes_hor, lanes_img_hor);
        cv::imshow(OPENCV_WINDOW_lanes_vert, lanes_img_vert);
        cv::waitKey(3);

//        char k;
//        k = cv::waitKey(3);  // wait 3 sec before next image
//        //printf("%d\n", k);
//        if(k == 10) // save if "Enter" is clicked
//        {
//            // save images + H + CalibConfig
//            //cv::imwrite("presentation_topview.jpg", topview_img);
//            cv::imwrite("presentation_centerLines_hor.jpg", lines_img_hor);
//            cv::imwrite("presentation_centerLines_vert.jpg", lines_img_vert);
//            cv::imwrite("presentation_PolyLines_hor.jpg", lanes_img_hor);
//            cv::imwrite("presentation_PolyLines_vert.jpg", lanes_img_vert);
//        }




    }


    void loadDoubleMatFromFile(cv::Mat& m, const char* filename, int rows, int cols)
    {
        double a;
        int rowCount = 1;
        int colCount = 0;
        std::ifstream myfile (filename);
        if (myfile.is_open())
        {
        while ( myfile >> a)
        {
            colCount++;
            if(colCount > cols)
            {
                colCount = 1;
                rowCount++;
            }
            if(rowCount > rows) break;

            m.at<double>(rowCount-1,colCount-1) = a;
        }
        myfile.close();
        }
        else std::cout << "Unable to open file";
    }


    void loadCalibConfigFromFile(cv::Size& topviewSize, cv::Point& carPos, const char* filename)
    {
        std::ifstream myfile (filename);
        if (myfile.is_open())
        {
        myfile >> topviewSize.width;
        myfile >> topviewSize.height;
        myfile >> carPos.x;
        myfile >> carPos.y;
        myfile.close();
        }
        else std::cout << "Unable to open file";
    }


    void birdsEyeTransform(cv::Mat& inputImg, cv::Mat& outputImg, cv::Mat& projMat, cv::Size& topviewSize)
    {
        // transformate image
        cv::warpPerspective(inputImg, outputImg, projMat, topviewSize, CV_INTER_LINEAR | CV_WARP_INVERSE_MAP | CV_WARP_FILL_OUTLIERS, cv::BORDER_CONSTANT, TOPVIEW_BACKGROUND ) ;
    }

    void postprocessTopview(cv::Mat& dstImg, bool& resizeOutput, cv::Point& carPos, bool& visCarPos)
    {
        if(visCarPos)
        {
            cv::circle(dstImg, carPos, 5, CV_RGB(0,255,0), -1);
            cv::line(dstImg,cv::Point(0,0),cv::Point(NEIGHBOR_KERNEL_SIZE,0),cv::Scalar(0,0,255,0),3);
        }
        if(resizeOutput)
        {
            cv::resize(dstImg, dstImg, cv::Size(), .5, .5 );
        }
    }

    void detectLaneMarks(cv::Mat& inputImg, cv::Mat& dstLines_hor, cv::Mat& dstLines_vert, cv::Mat& dstLanes_hor, cv::Mat& dstLanes_vert, cv::Point& carPos, cv::Mat& meanNeighborKernel)
    {
        //Todos: local threshold approach + line classification
        //- extraktionskarte befüllen(thresholding)
        //- mit Kernel über extraktionskarte gehen(horizontal bzw vertikal)

        cv::Mat inputGray, lineExtractMask_hor, lineExtractMask_vert, binaryLines_hor, binaryLines_vert, lineContourIndexMap_hor, lineContourIndexMap_vert,
                centerLineImg_hor, centerLineImg_vert, polyLinesImg_hor, polyLinesImg_vert;
        cv::cvtColor(inputImg, inputGray, CV_RGB2GRAY);

        centerLineImg_hor = cv::Mat::zeros(inputGray.rows, inputGray.cols, inputGray.type());
        centerLineImg_vert = cv::Mat::zeros(inputGray.rows, inputGray.cols, inputGray.type());
        polyLinesImg_hor = cv::Mat::zeros(inputGray.rows, inputGray.cols, inputImg.type());
        polyLinesImg_vert = cv::Mat::zeros(inputGray.rows, inputGray.cols, inputImg.type());
        binaryLines_hor = cv::Mat::zeros(inputGray.rows, inputGray.cols, inputGray.type());
        binaryLines_vert = cv::Mat::zeros(inputGray.rows, inputGray.cols, inputGray.type());
        lineContourIndexMap_hor = cv::Mat::ones(inputGray.rows, inputGray.cols, inputGray.type());
        lineContourIndexMap_vert = cv::Mat::ones(inputGray.rows, inputGray.cols, inputGray.type());


        //cv::Vec3b intensity = inputImg.at<cv::Vec3b>(0, 0);
        //float a = ;
        //ROS_INFO_STREAM("[" << neighborKern.at<float>(0,0));
        //ROS_INFO_STREAM("[" << (int)intensity.val[0] << "," << (int)intensity.val[1] << "," << (int)intensity.val[2] << "]");

        // detect lines
        detectLines(inputGray, lineExtractMask_hor, lineExtractMask_vert, centerLineImg_hor, centerLineImg_vert, LINE_DETECTION_THRESHOLD);

        //TODO:
        // --> fuse hor and vert and solve doubles


        // ------------------------
        // classify lines
        // ------------------------



        // get orientation of lines

        // Find all the contours in the thresholded image
        cv::Mat contourImg_hor, contourInputCpy_hor, contourImg_vert, contourImg_all, contourInputCpy_vert;
        contourImg_hor.create(lineExtractMask_hor.rows, lineExtractMask_hor.cols, CV_8UC3);
        contourImg_vert.create(lineExtractMask_vert.rows, lineExtractMask_vert.cols, CV_8UC3);
        contourImg_all.create(lineExtractMask_vert.rows, lineExtractMask_vert.cols, CV_8UC3);
        contourInputCpy_hor = lineExtractMask_hor.clone();
        contourInputCpy_vert = lineExtractMask_vert.clone();

        std::vector<std::vector<cv::Point> > contours_hor, contours_vert, /*contours_all,*/ lineContours_hor, lineContours_vert, polyLines_hor, polyLines_vert;
        //std::vector<std::vector<std::vector<cv::Point> > > lineSegsContours_hor, lineSegsContours_vert;


        std::vector<std::vector<cv::Point2d> > eigenVecs_hor, eigenVecs_vert;
        std::vector<std::vector<double> > eigenVals_hor, eigenVals_vert;
        std::vector<cv::Point> centers_hor, centers_vert;

        //std::vector<cv::Vec4i> hierarchy_hor, hierarchy_vert;
        cv::findContours(contourInputCpy_hor, contours_hor, /*hierarchy_hor,*/ CV_RETR_EXTERNAL/*CV_RETR_LIST*/, CV_CHAIN_APPROX_NONE);
        cv::findContours(contourInputCpy_vert, contours_vert, /*hierarchy_vert,*/ CV_RETR_EXTERNAL/*CV_RETR_LIST*/, CV_CHAIN_APPROX_NONE);

        int appendID = -1;
        for (size_t i = 0; i < contours_hor.size(); ++i)
        {
            // Calculate the area of each contour
            double area = cv::contourArea(contours_hor[i]);
            // Ignore contours that are too small or too large
            if (area < 1e2 || 1e5 < area) continue;                        

            //append pca values for analysis
            appendPcaValuesOfContour(contours_hor[i], eigenVecs_hor, eigenVals_hor, centers_hor);
            appendID++;

            // check if it is a line --> if eigenval[0]> 2*eigenval[1]  and delete if its not
            if(! (eigenVals_hor[appendID][0] > 10* eigenVals_hor[appendID][1]) )
            {
                eigenVals_hor.pop_back();
                eigenVecs_hor.pop_back();
                centers_hor.pop_back();
                //contours_hor.erase(i);
                appendID--;
                continue;
            }
            else
            {
                std::vector<cv::Point> lineContour = contours_hor[i];
                lineContours_hor.push_back(lineContour);

//                std::vector<cv::Point> centerLineContour;
//                calcCenterLineOfContour(lineContour, lineExtractMask_hor, centerLineContour, false);
//                centerLineContour_hor.push_back(centerLineContour);
//                //cv::drawContours(contourImg_hor, centerLineContour_hor, appendID,cv::Scalar(255,255,255), 1, 8);
//                for (int k = 0; k < centerLineContour_hor[appendID].size(); ++k)
//                {
//                    cv::circle(centerLineImg_hor, centerLineContour_hor[appendID][k], 1, CV_RGB(255, 255, 255), -1);
//                }
            }

            //contours_all.push_back(contours_hor[i]);

            // Draw each contour only for visualisation purposes
            cv::drawContours(contourImg_hor, lineContours_hor, appendID, cv::Scalar(0,0,255), 2, 8/*, hierarchy_hor, 0*/);
            cv::drawContours(binaryLines_hor, lineContours_hor, appendID, cv::Scalar(255,255,255), -1, 8);
            calcIndexMapOfContour(lineContours_hor[appendID], lineContourIndexMap_hor, appendID);
            //if(!(centers_hor.empty())){ROS_INFO_STREAM(" centers_hor[" << i << "]: " << (int)centers_hor[i].x << ", " << (int)centers_hor[i].y);}
            //if(!(eigenVecs_hor.empty())){ROS_INFO_STREAM(" eigenVecs_hor[" << i << "]: " << eigenVecs_hor[i][0].x << ", " << eigenVecs_hor[i][0].y);}
            //if(!(eigenVals_hor.empty())){ROS_INFO_STREAM(" eigenVals_hor[" << i << "]: " /*<< eigenVals_hor[i][0] << ", " << eigenVals_hor[i][0]*/);}
            //cv::waitKey(500);

            if(appendID != -1)
            {
                drawPcaValues(contourImg_hor, centers_hor[appendID], eigenVecs_hor[appendID], eigenVals_hor[appendID]);
            }
        }

        appendID = -1;
        for (size_t i = 0; i < contours_vert.size(); ++i)
        {
            // Calculate the area of each contour
            double area = cv::contourArea(contours_vert[i]);
            // Ignore contours that are too small or too large
            if (area < 1e2 || 1e5 < area) continue;

            //append pca values for analysis
            appendPcaValuesOfContour(contours_vert[i], eigenVecs_vert, eigenVals_vert, centers_vert);
            appendID++;

            // check if it is a line --> if eigenval[0]> 2*eigenval[1]  and delete if its not
            if(! (eigenVals_vert[appendID][0] > 10* eigenVals_vert[appendID][1]) )
            {
                eigenVals_vert.pop_back();
                eigenVecs_vert.pop_back();
                centers_vert.pop_back();
                //contours_vert.erase(i);
                appendID--;
                continue;
            }
            else
            {
                std::vector<cv::Point> lineContour = contours_vert[i];
                lineContours_vert.push_back(lineContour);

//                std::vector<cv::Point> centerLineContour;
//                calcCenterLineOfContour(lineContour, lineExtractMask_vert, centerLineContour, true);
//                centerLineContour_vert.push_back(centerLineContour);
//                //cv::drawContours(contourImg_vert, centerLineContour_vert, appendID,cv::Scalar(255,255,255), 1, 8);
//                for (int k = 0; k < centerLineContour_vert[appendID].size(); ++k)
//                {
//                    cv::circle(centerLineImg_vert, centerLineContour_vert[appendID][k], 1, CV_RGB(255, 255, 255), -1);
//                }
            }


            // TODO:check if its already in
//            for (size_t k = 0; k < contours_hor.size(); ++k)
//            {
//                //1.: center and orientation
//                //2. calc distance of every point of contour
//                // --> min distance, howmuch lies inside or on edge
//                //cv::pointPolygonTest()
//            }

            //contours_all.push_back(contours_vert[i]);

            // Draw each contour only for visualisation purposes
            cv::drawContours(contourImg_vert, lineContours_vert, appendID, cv::Scalar(0,255,0), 2, 8/*, hierarchy_vert, 0*/);
            cv::drawContours(binaryLines_vert, lineContours_vert, appendID, cv::Scalar(255,255,255), -1, 8);
            calcIndexMapOfContour(lineContours_vert[appendID], lineContourIndexMap_vert, appendID);
            //TODO: bigger kernel
            //cv::erode(binaryLines_vert, binaryLines_vert, cv::Mat(),cv::Point(-1,-1),1);
            //cv::dilate(binaryLines_vert, binaryLines_vert, cv::Mat(),cv::Point(-1,-1),1);
//            for (int k = 0; k < contours_vert[i].size(); ++k)
//            {
//                cv::circle(contourImg_vert, contours_vert[i][k], 1, CV_RGB(255, 0, 0), -1);
//            }
            //appendLineSegmentsOfContour(contours_vert[i], contourImg_vert, lineSegsContours_vert);
            if(appendID != -1)
            {
                drawPcaValues(contourImg_vert, centers_vert[appendID], eigenVecs_vert[appendID], eigenVals_vert[appendID]);
            }
        }


        std::vector<std::vector<cv::Point> > centerLineContours_hor(lineContours_hor.size()), centerLineContours_vert(lineContours_vert.size());
        calcCenterLinesOfBinaryLineImage(binaryLines_hor, lineContourIndexMap_hor, centerLineImg_hor, centerLineContours_hor, true);
        calcCenterLinesOfBinaryLineImage(binaryLines_vert, lineContourIndexMap_vert, centerLineImg_vert, centerLineContours_vert, false);
        approxCenterLines(centerLineContours_hor, polyLines_hor, 3);
        approxCenterLines(centerLineContours_vert, polyLines_vert, 3);
        drawPolyLines(polyLines_hor, polyLinesImg_hor);
        drawPolyLines(polyLines_vert, polyLinesImg_vert);


//        for (size_t i = 0; i < contours_all.size(); ++i)
//        {
//            cv::drawContours(contourImg_all, contours_all,i,cv::Scalar(255,255,0));
//        }
        // fuse contours


        // ------------------------

        dstLines_hor = centerLineImg_hor;//lineWidthMap_hor;
        dstLines_vert = centerLineImg_vert;
        dstLanes_hor = polyLinesImg_hor;
        dstLanes_vert = polyLinesImg_vert;
    }


    void detectLines(cv::Mat& inputGray, cv::Mat& dstLines_hor, cv::Mat& dstLines_vert, cv::Mat& dstLineWidthMap_hor, cv::Mat& dstLineWidthMap_vert, int& threshold)
    {
        //TODOS:
        // - threshold an helligkeit anpassen
        //int border = 0;
        //int borderCounter;

        cv::Mat meanNeighbor_hor, meanNeighbor_vert, meanNeighborKernel_vert;

        // init mat
        dstLines_hor = inputGray.clone();
        dstLines_vert = inputGray.clone();
        //dstLineWidthMap_hor = inputGray.clone();
        //dstLineWidthMap_vert = inputGray.clone();
        //dstLines_hor = cv::Mat::zeros(inputGray.rows, inputGray.cols, inputGray.type());
        //dstLines_vert = cv::Mat::zeros(inputGray.rows, inputGray.cols, inputGray.type());
        //dstLineWidthMap_hor = cv::Mat::zeros(inputGray.rows, inputGray.cols, inputGray.type());
        //dstLineWidthMap_vert = cv::Mat::zeros(inputGray.rows, inputGray.cols, inputGray.type());

        cv::filter2D(inputGray, meanNeighbor_hor, -1, meanNeighborKernel);
        cv::transpose(meanNeighborKernel,meanNeighborKernel_vert);
        cv::filter2D(inputGray, meanNeighbor_vert, -1, meanNeighborKernel_vert);

        //int widthCntr;
        //int threshold = 40;
        for (int x = 0; x < inputGray.cols; x++)
        {
            //widthCntr = 0;
            //borderCounter = border;
            for (int y = 0; y < inputGray.rows; y++)
            {
                uchar& pixVal_hor = dstLines_hor.at<uchar>(y, x);
                uchar& pixVal_vert = dstLines_vert.at<uchar>(y, x);
                //uchar& widthVal_hor = dstLineWidthMap_hor.at<uchar>(y, x);
                //uchar& widthVal_vert = dstLineWidthMap_vert.at<uchar>(y, x);
                uchar pixVal_input = inputGray.at<uchar>(y, x);
                uchar meanNeighborVal_hor = meanNeighbor_hor.at<uchar>(y, x);
                uchar meanNeighborVal_vert = meanNeighbor_vert.at<uchar>(y, x);
                // if pixel is outside of topview
                if(TOPVIEW_BACKGROUND_GRAY == (int)pixVal_input){
                    // do nothing
                }
                // if pixel is inside of topview
                else
                {
//                    if(borderCounter == 0)
//                    {
                        // horizontal lines
                        if((int)pixVal_input > threshold + (int)meanNeighborVal_hor)
                        {
                            //ROS_INFO_STREAM("I:" << (int)pixVal_hor << " M:" << (int)meanNeighborVal_hor);
                            pixVal_hor = 255;
                        }
                        else
                        {
                            pixVal_hor = 0;
                        }

                        // vertical lines
                        if((int)pixVal_input > threshold + (int)meanNeighborVal_vert)
                        {
                            pixVal_vert = 255;                            
                            //widthCntr++;
                        }
                        else
                        {
                            pixVal_vert = 0;
//                            if(widthCntr != 0)
//                            {
//                                uchar& widthVal_vert = dstLineWidthMap_vert.at<uchar>(y-(1+((int)(widthCntr/2))), x);
//                                widthVal_vert = 255;
//                            }
//                            widthCntr = 0;
                        }
//                    }
//                    else
//                    {
//                        borderCounter--;
//                    }
                }
            }
        }


//        for (int y = 0; y < inputGray.rows; y++)
//        {
//            //widthCntr = 0;
//            //borderCounter = border;
//            for (int x = 0; x < inputGray.cols; x++)
//            {
//                uchar pixVal_hor = dstLines_hor.at<uchar>(y, x);
//                uchar pixVal_input = inputGray.at<uchar>(y, x);

//                // if pixel is outside of topview
//                if(TOPVIEW_BACKGROUND_GRAY == (int)pixVal_input){
//                    // do nothing
//                }
//                // if pixel is inside of topview
//                else
//                {
//                    if(borderCounter == 0)
//                    {
//                        // horizontal lines
//                        if((int)pixVal_hor == 255)
//                        {
//                            //widthVal_hor = 255- widthCntr;
//                            widthCntr++;
//                        }
//                        else
//                        {
//                            if(widthCntr != 0)
//                            {
//                                uchar& widthVal_hor = dstLineWidthMap_hor.at<uchar>(y, x-(1+((int)(widthCntr/2))));
//                                widthVal_hor= 255;
//                            }
//                            widthCntr = 0;
//                        }
//                    }
//                    else
//                    {
//                        borderCounter--;
//                    }

//                }
//            }
//        }
    }


    void createMeanNeighborKernel(cv::Mat& dstKernel, int kernelSize)
    {
        float kernElem = (float) 1/(kernelSize-1);
        int Myanchor = (int)(kernelSize-1) / 2;
        cv::Mat neighborKern;
        neighborKern.create(1,kernelSize,CV_32FC1);

        for(int i = 0; i<kernelSize; i++)
        {
            float& pixVal = neighborKern.at<float>(0,i);
            if(i == Myanchor)
            {
                pixVal = 0.0;
            }
            pixVal = kernElem;
        }

        dstKernel = neighborKern;
    }


    void drawPcaValues(cv::Mat& dstImg, cv::Point& pos, std::vector<cv::Point2d>& eigen_vecs, std::vector<double>& eigen_val)
    {
        // Draw the principal components
        cv::circle(dstImg, pos, 3, CV_RGB(255, 0, 255), 2);
        cv::line(dstImg, pos, pos + 0.02 * cv::Point(eigen_vecs[0].x * eigen_val[0], eigen_vecs[0].y * eigen_val[0]) , CV_RGB(255, 255, 0));
        cv::line(dstImg, pos, pos + 0.02 * cv::Point(eigen_vecs[1].x * eigen_val[1], eigen_vecs[1].y * eigen_val[1]) , CV_RGB(0, 255, 255));
    }


    void appendPcaValuesOfContour(std::vector<cv::Point> &pts, std::vector<std::vector<cv::Point2d> >& dstEigenVecs, std::vector<std::vector<double> >& dstEigenVals, std::vector<cv::Point> &dstMeans)
    {
        std::vector<cv::Point2d> tmpEigen_vecs(2);
        std::vector<double> tmpEigen_vals(2);
        cv::Point tmpMean;

        //Construct a buffer used by the pca analysis
        cv::Mat data_pts = cv::Mat(pts.size(), 2, CV_64FC1);
        for (int i = 0; i < data_pts.rows; ++i)
        {
            data_pts.at<double>(i, 0) = pts[i].x;
            data_pts.at<double>(i, 1) = pts[i].y;
        }

        //Perform PCA analysis
        cv::PCA pca_analysis(data_pts, cv::Mat(), CV_PCA_DATA_AS_ROW);

        //Store the position of the object
        tmpMean = cv::Point(pca_analysis.mean.at<double>(0, 0),
                          pca_analysis.mean.at<double>(0, 1));

        for (int i = 0; i < 2; ++i)
        {
            tmpEigen_vecs[i] = cv::Point2d(pca_analysis.eigenvectors.at<double>(i, 0),
                                    pca_analysis.eigenvectors.at<double>(i, 1));

            tmpEigen_vals[i] = pca_analysis.eigenvalues.at<double>(0, i);
        }

        dstEigenVecs.push_back(tmpEigen_vecs);
        dstEigenVals.push_back(tmpEigen_vals);
        dstMeans.push_back(tmpMean);
    }

    void drawPolyLines(std::vector<std::vector<cv::Point> > &inputPolyLines, cv::Mat &dstImg)
    {
        for(int i=0; i<inputPolyLines.size(); i++)
        {
            for(int k=0; k<inputPolyLines[i].size()-1; k++)
            {
                cv::line(dstImg, inputPolyLines[i][k], inputPolyLines[i][k+1], CV_RGB(0,255,255));
            }
        }
    }


    void approxCenterLines(std::vector<std::vector<cv::Point> > &inputCenterLines, std::vector<std::vector<cv::Point> > &dstPolyLines, float epsilon)
    {
        for(int i=0; i<inputCenterLines.size(); i++)
        {
            std::vector<cv::Point> polyLine;
            cv::approxPolyDP(inputCenterLines[i], polyLine, epsilon, false);
            dstPolyLines.push_back(polyLine);
        }
    }


    void calcIndexMapOfContour(std::vector<cv::Point> & inputContour, cv::Mat & indexMap, int &index)
    {
        for(int i=0; i<inputContour.size(); i++)
        {
            cv::Point current = inputContour[i];
            uchar& pixVal = indexMap.at<uchar>(current.y, current.x);
            pixVal = index;
        }
    }


    void calcCenterLinesOfBinaryLineImage(cv::Mat &inputBinaryImg, cv::Mat &contourIndexMap, cv::Mat &centerLineImg,
                                          std::vector<std::vector<cv::Point> > &centerLines, bool horizontalLines)
    {
        // init mat
        centerLineImg = cv::Mat::zeros(inputBinaryImg.rows, inputBinaryImg.cols, inputBinaryImg.type());

        int widthCntr;
        bool gotLine;
        int currentIndex = -1;

        if(!horizontalLines)
        {
            for (int x = 0; x < inputBinaryImg.cols; x++)
            {
                widthCntr = 0;
                gotLine = false;
                for (int y = 0; y < inputBinaryImg.rows; y++)
                {
                    uchar pixValBin = inputBinaryImg.at<uchar>(y, x);

                    if(255 == (int)pixValBin && gotLine == false)
                    {
                        uchar pixValIndex = contourIndexMap.at<uchar>(y, x);

                        // no line index found
                        if((int)pixValIndex == 255) continue;
                        //new line index found
                        else if((int)pixValIndex != 255 )
                        {
                            gotLine = true;
                            currentIndex = (int)pixValIndex;
                            widthCntr++;
                        }
                    }
                    //line width in progress
                    else if(255 == (int)pixValBin && gotLine == true)
                    {
                        widthCntr++;
                    }
                    // end of line found
                    else if(0 == (int)pixValBin && gotLine == true)
                    {
                        uchar& centerLineVal = centerLineImg.at<uchar>(y-(1+((int)(widthCntr/2))), x);
                        centerLineVal = 255;
                        cv::Point tmpPoint(x,y-(1+((int)(widthCntr/2))));
                        centerLines[currentIndex].push_back(tmpPoint);
                        currentIndex = -1;
                        gotLine = false;
                    }
                }
            }
        }
        //vertical Lines
        else
        {
            for (int y = 0; y < inputBinaryImg.rows; y++)
            {
                widthCntr = 0;
                gotLine = false;
                for (int x = 0; x < inputBinaryImg.cols; x++)
                {
                    uchar pixValBin = inputBinaryImg.at<uchar>(y, x);

                    if(255 == (int)pixValBin && gotLine == false)
                    {
                        uchar pixValIndex = contourIndexMap.at<uchar>(y, x);

                        // no line index found
                        if((int)pixValIndex == 255) continue;
                        //new line index found
                        else if((int)pixValIndex != 255 )
                        {
                            gotLine = true;
                            currentIndex = (int)pixValIndex;
                            widthCntr++;
                        }
                    }
                    //line width in progress
                    else if(255 == (int)pixValBin && gotLine == true)
                    {
                        widthCntr++;
                    }
                    // end of line found
                    else if(0 == (int)pixValBin && gotLine == true)
                    {
                        uchar& centerLineVal = centerLineImg.at<uchar>(y, x-(1+((int)(widthCntr/2))));
                        centerLineVal = 255;
                        cv::Point tmpPoint(x-(1+((int)(widthCntr/2))),y);
                        centerLines[currentIndex].push_back(tmpPoint);
                        currentIndex = -1;
                        gotLine = false;
                    }
                }
            }
        }

    }


    void appendLineSegmentsOfContour(std::vector<cv::Point> &inputContour, cv::Mat& dstImg, std::vector<std::vector<std::vector<cv::Point> > > &dstLineSegsContours)
    {
        int segmentSize = 30;
        int contourSize = inputContour.size();

        if(contourSize < 2 * segmentSize)
        {
            segmentSize = (int)(contourSize / 2);
        }

        int segmentNum = (int) std::ceil(contourSize / segmentSize);

        std::vector<std::vector<cv::Point> > lineSegContour(segmentNum);

        //ROS_INFO_STREAM("contoursize:" << contourSize);
        //ROS_INFO_STREAM("segmentnum:" << segmentNum);
        for(int k=0; k< segmentNum; k++)
        {
            //ROS_INFO_STREAM("FOR 1.0:" << k);
            std::vector<cv::Point> lineSegment;

            for(int i=0; i< segmentSize; i++)
            {
                //ROS_INFO_STREAM("FOR 2:" << i);
                if((contourSize-1) < (i + k*segmentSize))
                {
                    break;
                }
                cv::Point tmpPoint;
                tmpPoint = inputContour[i + k*segmentSize];
                lineSegment.push_back(tmpPoint);
            }
            //ROS_INFO_STREAM("FOR 1.1:" << k);
            lineSegContour[k] = lineSegment;
            //ROS_INFO_STREAM("FOR 1.2:" << k);
            //Construct a buffer used by the pca analysis
            cv::Mat data_pts = cv::Mat(lineSegment.size(), 2, CV_64FC1);
            for (int i = 0; i < data_pts.rows; ++i)
            {
                data_pts.at<double>(i, 0) = lineSegment[i].x;
                data_pts.at<double>(i, 1) = lineSegment[i].y;
            }

            cv::PCA pca(data_pts, cv::Mat(), CV_PCA_DATA_AS_ROW);
            cv::Point center = cv::Point(pca.mean.at<double>(0, 0),
                              pca.mean.at<double>(0, 1));

            cv::circle(dstImg, center, 1, CV_RGB(255, 255, 0), -1);
        }

        dstLineSegsContours.push_back(lineSegContour);
    }


    double diffclock(clock_t clock1,clock_t clock2)
    {
        double diffticks=clock1-clock2;
        double diffms=(diffticks)/(CLOCKS_PER_SEC/1000);
        return diffms;
    }


    //    double getOrientation(std::vector<cv::Point> &pts, cv::Mat &img)
    //    {
    //        //Construct a buffer used by the pca analysis
    //        cv::Mat data_pts = cv::Mat(pts.size(), 2, CV_64FC1);
    //        for (int i = 0; i < data_pts.rows; ++i)
    //        {
    //            data_pts.at<double>(i, 0) = pts[i].x;
    //            data_pts.at<double>(i, 1) = pts[i].y;
    //        }

    //        //Perform PCA analysis
    //        cv::PCA pca_analysis(data_pts, cv::Mat(), CV_PCA_DATA_AS_ROW);

    //        //Store the position of the object
    //        cv::Point pos = cv::Point(pca_analysis.mean.at<double>(0, 0),
    //                          pca_analysis.mean.at<double>(0, 1));


    //        //Store the eigenvalues and eigenvectors
    //        std::vector<cv::Point2d> eigen_vecs(2);
    //        std::vector<double> eigen_val(2);
    //        for (int i = 0; i < 2; ++i)
    //        {
    //            eigen_vecs[i] = cv::Point2d(pca_analysis.eigenvectors.at<double>(i, 0),
    //                                    pca_analysis.eigenvectors.at<double>(i, 1));

    //            eigen_val[i] = pca_analysis.eigenvalues.at<double>(0, i);
    //        }

    //        // Draw the principal components
    //        cv::circle(img, pos, 3, CV_RGB(255, 0, 255), 2);
    //        cv::line(img, pos, pos + 0.02 * cv::Point(eigen_vecs[0].x * eigen_val[0], eigen_vecs[0].y * eigen_val[0]) , CV_RGB(255, 255, 0));
    //        cv::line(img, pos, pos + 0.02 * cv::Point(eigen_vecs[1].x * eigen_val[1], eigen_vecs[1].y * eigen_val[1]) , CV_RGB(0, 255, 255));

    //        //return std::atan2(eigen_vecs[0].y, eigen_vecs[0].x);
    //    }


    //    void calcCenterLineOfContour(std::vector<cv::Point> &inputContour, cv::Mat &inputBinaryImg, std::vector<cv::Point> &dstCenterLine, bool horizontalDir)
    //    {
    //        //theoretical, the contour have to be rotated arround her mean point with her orientation before the process and rotated back afterwards
    //        cv::Point currentPoint;
    //        bool processPoint = false;
    //        int minY, maxY, minX, maxX;
    //        for(int i=0; i < inputContour.size(); i++)
    //        {
    //            currentPoint = inputContour[i];

    //            if(horizontalDir)
    //            {
    //                // check if new point is neccessary
    //                if(i != 0)
    //                {
    //                    if(currentPoint.x < minX || currentPoint.x > maxX)
    //                    {
    //                        processPoint = true;
    //                    }
    //                    else processPoint = false;
    //                }
    //                else
    //                {
    //                    minX = currentPoint.x;
    //                    maxX = currentPoint.x;
    //                    processPoint = true;
    //                }
    //                // if neccessary, process
    //                if(processPoint)
    //                {
    //                    int linIter = 0;
    //                    bool downDir = true;
    //                    bool noLineEnd = true;
    //                    // get center Point to contour point and binary line image
    //                    uchar pixVal_input_up = inputBinaryImg.at<uchar>(currentPoint.y-1, currentPoint.x);
    //                    uchar pixVal_input_down = inputBinaryImg.at<uchar>(currentPoint.y+1, currentPoint.x);

    //                    if(255 == (int)pixVal_input_up && 255 == (int)pixVal_input_down)
    //                    {
    //                        ROS_ERROR_STREAM("ERROR in getCenterLineOfContour: contour point is not on an edge of a line! horizontal line");
    //                    }
    //                    else if(255 == (int)pixVal_input_up)
    //                    {
    //                        linIter--;
    //                        downDir = false;
    //                    }
    //                    else if(255 == (int)pixVal_input_down)
    //                    {
    //                        linIter++;
    //                        downDir = true;
    //                    }
    //                    else    noLineEnd = false;

    //                    while(noLineEnd)
    //                    {
    //                        if(downDir)    linIter++;
    //                        else            linIter--;
    //                        pixVal_input_up = inputBinaryImg.at<uchar>(currentPoint.y+linIter, currentPoint.x);
    //                        if(0 == (int)pixVal_input_up)         noLineEnd = false;
    //                    }
    //                    cv::Point centerLinePoint(currentPoint.x, currentPoint.y+((int)(linIter/2)));
    //                    dstCenterLine.push_back(centerLinePoint);
    //                    if(currentPoint.x < minX)   minX = currentPoint.x;
    //                    if(currentPoint.x > maxX)   maxX = currentPoint.x;
    //                }
    //            }
    //            else
    //            {
    //                // check if new point is neccessary
    //                if(i != 0)
    //                {
    //                    if(currentPoint.y < minY || currentPoint.y > maxY)
    //                    {
    //                        processPoint = true;
    //                    }
    //                    else processPoint = false;
    //                }
    //                else
    //                {
    //                    minY = currentPoint.y;
    //                    maxY = currentPoint.y;
    //                    processPoint = true;
    //                }
    //                // if neccessary, process
    //                if(processPoint)
    //                {
    //                    int linIter = 0;
    //                    bool rightDir = true;
    //                    bool noLineEnd = true;
    //                    // get center Point to contour point and binary line image
    //                    uchar pixVal_input_left = inputBinaryImg.at<uchar>(currentPoint.y, currentPoint.x-1);
    //                    uchar pixVal_input_right = inputBinaryImg.at<uchar>(currentPoint.y, currentPoint.x+1);

    //                    if(255 == (int)pixVal_input_left && 255 == (int)pixVal_input_right)
    //                    {
    //                        ROS_ERROR_STREAM("ERROR in getCenterLineOfContour: contour point is not on an edge of a line! vertical line");
    //                    }
    //                    else if(255 == (int)pixVal_input_left)
    //                    {
    //                        linIter--;
    //                        rightDir = false;
    //                    }
    //                    else if(255 == (int)pixVal_input_right)
    //                    {
    //                        linIter++;
    //                        rightDir = true;
    //                    }
    //                    else    noLineEnd = false;

    //                    while(noLineEnd)
    //                    {
    //                        if(rightDir)    linIter++;
    //                        else            linIter--;
    //                        pixVal_input_left = inputBinaryImg.at<uchar>(currentPoint.y, currentPoint.x+linIter);
    //                        if(0 == (int)pixVal_input_left)         noLineEnd = false;
    //                    }
    //                    cv::Point centerLinePoint(currentPoint.x+((int)(linIter/2)), currentPoint.y);
    //                    dstCenterLine.push_back(centerLinePoint);
    //                    if(currentPoint.y < minY)   minY = currentPoint.y;
    //                    if(currentPoint.y > maxY)   maxY = currentPoint.y;
    //                }
    //            }

    //        }
    //    }
};

int main(int argc, char** argv)
{
    ros::init(argc, argv, "visLoc");
    OttoCarVisLoc visLoc;
    ros::spin();
    return 0;
}

